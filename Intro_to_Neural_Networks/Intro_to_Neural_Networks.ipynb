{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "id": "RrG8vTDSAzVM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('medical_cost_data.csv')\n",
    "\n",
    "y_colname = 'charges'\n",
    "y = data[y_colname]\n",
    "X = data.drop([y_colname], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "cols_to_transform = ['sex', 'region']\n",
    "\n",
    "\n",
    "# Function to one-hot-encode categorical features\n",
    "def ohe_transform_cat_feats(ohe, X):\n",
    "    cols_to_transform = ['sex', 'region']\n",
    "    # Use the OneHotEncoder to create a new matrix\n",
    "    X_gen_trans = ohe.transform(X[cols_to_transform]).toarray()\n",
    "    X_gen_trans = X_gen_trans.T\n",
    "\n",
    "    # Add the matrix rows as columns to the X DataFrame\n",
    "    new_col_names = ohe.get_feature_names_out()\n",
    "    for i, col in enumerate(new_col_names):\n",
    "        X[col] = X_gen_trans[i]\n",
    "\n",
    "    # Remove the unnecessary column and adjust the data types\n",
    "    # Explain why it is important to keep your dataset lean! (computational cost can explode quickly when scaling)\n",
    "    X = X.drop(cols_to_transform, axis=1)\n",
    "    X.loc[:, new_col_names] = X.loc[:, new_col_names].astype('int')\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "ohe.fit(X_train[cols_to_transform])\n",
    "\n",
    "X_train = ohe_transform_cat_feats(ohe, X_train)\n",
    "X_test = ohe_transform_cat_feats(ohe, X_test)\n",
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "X_test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "vW7RJsDkA0iB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687739302257,
     "user_tz": 360,
     "elapsed": 426,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "c37b72a8-07ce-4a3b-cfb0-82716b3500ae",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:43:55.052895Z",
     "start_time": "2023-06-27T17:43:55.020777Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0  age  height      weight     bmi  caloric_intake   \n764          764   45     181   82.475818  25.175            2814  \\\n887          887   36     194  112.983272  30.020            2833   \n890          890   64     170   77.697650  26.885            2933   \n1293        1293   46     188   90.993128  25.745            1763   \n259          259   19     162   83.770848  31.920            1940   \n...          ...  ...     ...         ...     ...             ...   \n644          644   43     179  113.136771  35.310            2995   \n602          602   56     173   75.720370  25.300            2277   \n731          731   53     165   58.261500  21.400            1821   \n321          321   26     177   92.859156  29.640            2473   \n479          479   23     184  110.235136  32.560            2541   \n\n      mean_heart_rate  glucose_levels  children  work_hours       income   \n764         83.612513        4.373338         2    8.473943  1000.509934  \\\n887         66.371988        4.652292         0    8.642828  1162.168417   \n890         92.959231        4.117142         0   10.276023  1014.796519   \n1293        59.467169        4.609396         3    8.742813  1001.131353   \n259         83.358230        5.063206         0    9.766670  1001.728314   \n...               ...             ...       ...         ...          ...   \n644         96.382310        4.285086         2    6.660268  1004.907353   \n602         52.323727        5.252695         0    8.462220  1003.221429   \n731         59.682528        5.076635         1    9.615741  1220.491675   \n321         85.658888        4.583662         4    8.954053  1000.017595   \n479         74.949640        4.473633         0    7.465420  1001.502508   \n\n      sex_female  sex_male  region_northeast  region_northwest   \n764          1.0       0.0               1.0               0.0  \\\n887          1.0       0.0               0.0               1.0   \n890          1.0       0.0               0.0               1.0   \n1293         0.0       1.0               0.0               1.0   \n259          0.0       1.0               0.0               1.0   \n...          ...       ...               ...               ...   \n644          0.0       1.0               0.0               0.0   \n602          1.0       0.0               0.0               0.0   \n731          0.0       1.0               0.0               0.0   \n321          1.0       0.0               1.0               0.0   \n479          0.0       1.0               0.0               0.0   \n\n      region_southeast  region_southwest  \n764                0.0               0.0  \n887                0.0               0.0  \n890                0.0               0.0  \n1293               0.0               0.0  \n259                0.0               0.0  \n...                ...               ...  \n644                1.0               0.0  \n602                0.0               1.0  \n731                0.0               1.0  \n321                0.0               0.0  \n479                1.0               0.0  \n\n[442 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>age</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>bmi</th>\n      <th>caloric_intake</th>\n      <th>mean_heart_rate</th>\n      <th>glucose_levels</th>\n      <th>children</th>\n      <th>work_hours</th>\n      <th>income</th>\n      <th>sex_female</th>\n      <th>sex_male</th>\n      <th>region_northeast</th>\n      <th>region_northwest</th>\n      <th>region_southeast</th>\n      <th>region_southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>764</th>\n      <td>764</td>\n      <td>45</td>\n      <td>181</td>\n      <td>82.475818</td>\n      <td>25.175</td>\n      <td>2814</td>\n      <td>83.612513</td>\n      <td>4.373338</td>\n      <td>2</td>\n      <td>8.473943</td>\n      <td>1000.509934</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>887</td>\n      <td>36</td>\n      <td>194</td>\n      <td>112.983272</td>\n      <td>30.020</td>\n      <td>2833</td>\n      <td>66.371988</td>\n      <td>4.652292</td>\n      <td>0</td>\n      <td>8.642828</td>\n      <td>1162.168417</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>890</td>\n      <td>64</td>\n      <td>170</td>\n      <td>77.697650</td>\n      <td>26.885</td>\n      <td>2933</td>\n      <td>92.959231</td>\n      <td>4.117142</td>\n      <td>0</td>\n      <td>10.276023</td>\n      <td>1014.796519</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1293</th>\n      <td>1293</td>\n      <td>46</td>\n      <td>188</td>\n      <td>90.993128</td>\n      <td>25.745</td>\n      <td>1763</td>\n      <td>59.467169</td>\n      <td>4.609396</td>\n      <td>3</td>\n      <td>8.742813</td>\n      <td>1001.131353</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>259</td>\n      <td>19</td>\n      <td>162</td>\n      <td>83.770848</td>\n      <td>31.920</td>\n      <td>1940</td>\n      <td>83.358230</td>\n      <td>5.063206</td>\n      <td>0</td>\n      <td>9.766670</td>\n      <td>1001.728314</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>644</td>\n      <td>43</td>\n      <td>179</td>\n      <td>113.136771</td>\n      <td>35.310</td>\n      <td>2995</td>\n      <td>96.382310</td>\n      <td>4.285086</td>\n      <td>2</td>\n      <td>6.660268</td>\n      <td>1004.907353</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>602</th>\n      <td>602</td>\n      <td>56</td>\n      <td>173</td>\n      <td>75.720370</td>\n      <td>25.300</td>\n      <td>2277</td>\n      <td>52.323727</td>\n      <td>5.252695</td>\n      <td>0</td>\n      <td>8.462220</td>\n      <td>1003.221429</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>731</th>\n      <td>731</td>\n      <td>53</td>\n      <td>165</td>\n      <td>58.261500</td>\n      <td>21.400</td>\n      <td>1821</td>\n      <td>59.682528</td>\n      <td>5.076635</td>\n      <td>1</td>\n      <td>9.615741</td>\n      <td>1220.491675</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>321</td>\n      <td>26</td>\n      <td>177</td>\n      <td>92.859156</td>\n      <td>29.640</td>\n      <td>2473</td>\n      <td>85.658888</td>\n      <td>4.583662</td>\n      <td>4</td>\n      <td>8.954053</td>\n      <td>1000.017595</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>479</td>\n      <td>23</td>\n      <td>184</td>\n      <td>110.235136</td>\n      <td>32.560</td>\n      <td>2541</td>\n      <td>74.949640</td>\n      <td>4.473633</td>\n      <td>0</td>\n      <td>7.465420</td>\n      <td>1001.502508</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>442 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First Neural Network"
   ],
   "metadata": {
    "id": "d1astEBfA2lJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "id": "SqTdwwh-Dk8h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687739309427,
     "user_tz": 360,
     "elapsed": 4924,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "3d0d9830-b6b8-456b-bc0f-bb1a489c0db1",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:00.822912Z",
     "start_time": "2023-06-27T17:44:00.812312Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x140d3ce30>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# PyTorch (and TensorFlow) work with 'Tensors'!\n",
    "# Convert 'X' to a tensor\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert 'y' to a tensor\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)"
   ],
   "metadata": {
    "id": "U1qJgW52DL3v",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:03.659445Z",
     "start_time": "2023-06-27T17:44:03.645176Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7aA8f8J8_C0h",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:04.388802Z",
     "start_time": "2023-06-27T17:44:04.385051Z"
    }
   },
   "outputs": [],
   "source": [
    "n_hidden = X_train.shape[1] * 2\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(X_train.shape[1], n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, 4)\n",
    "        self.linear3 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=False)"
   ],
   "metadata": {
    "id": "YOG-FBCo_wIP",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:06.330998Z",
     "start_time": "2023-06-27T17:44:06.321722Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the network"
   ],
   "metadata": {
    "id": "vOuA15q4G39W"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_network(model, train_loader, num_epochs=200, verbose=True):\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = nn.MSELoss()  # Choose the loss function carefully, why aren't we using the R2 score?\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.6)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train the neural network\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if epoch % 10 == 0 and verbose:\n",
    "            print(f\"Epoch {epoch + 1} loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Use the above function to train the network\n",
    "model = train_network(model, train_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mZ1PwRi_yA2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740581139,
     "user_tz": 360,
     "elapsed": 5791,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "8dd7e3e1-3a5f-4ea6-dfc2-71b5467a70b5",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:16.185377Z",
     "start_time": "2023-06-27T17:44:15.098183Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 218731299.55555555\n",
      "Epoch 11 loss: 127670828.8888889\n",
      "Epoch 21 loss: 76452212.0\n",
      "Epoch 31 loss: 56564997.0\n",
      "Epoch 41 loss: 55245453.55555555\n",
      "Epoch 51 loss: 59290923.222222224\n",
      "Epoch 61 loss: 57000869.333333336\n",
      "Epoch 71 loss: 55635067.11111111\n",
      "Epoch 81 loss: 55306570.777777776\n",
      "Epoch 91 loss: 54935325.0\n",
      "Epoch 101 loss: 54166257.55555555\n",
      "Epoch 111 loss: 53291012.55555555\n",
      "Epoch 121 loss: 53241483.11111111\n",
      "Epoch 131 loss: 52733422.666666664\n",
      "Epoch 141 loss: 52272643.333333336\n",
      "Epoch 151 loss: 53618543.333333336\n",
      "Epoch 161 loss: 51979720.44444445\n",
      "Epoch 171 loss: 51103327.44444445\n",
      "Epoch 181 loss: 51267744.44444445\n",
      "Epoch 191 loss: 51225273.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network Playground\n",
    "\n",
    "https://playground.tensorflow.org"
   ],
   "metadata": {
    "id": "g1CBzgpTO1ii"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {
    "id": "IfyUZhO0G78e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the neural network on test data\n",
    "loss_fn = nn.MSELoss()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = loss_fn(test_outputs, y_test_tensor)\n",
    "print(\"Test loss (MSE):\", test_loss.item())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sECwdCjsG-F9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740388168,
     "user_tz": 360,
     "elapsed": 43,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "c7167983-9ac4-4814-9a66-b3189196eeb5",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:29.220264Z",
     "start_time": "2023-06-27T17:44:29.197911Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MSE): 56646748.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate using the R2 score"
   ],
   "metadata": {
    "id": "1GbiX_8fHGXo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define a function for model scoring\n",
    "def score_model(model, X_test_tensor, y_test):\n",
    "    # Make predictions using the model\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor)\n",
    "    y_pred = y_pred.numpy()\n",
    "    y_test_np = np.array(y_test.values)\n",
    "    # Compute the R2 score\n",
    "    score = r2_score(y_test_np, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "score_model(model, X_test_tensor, y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QB3o5C2BBHjp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740388168,
     "user_tz": 360,
     "elapsed": 22,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "df2aaff8-2c08-48ef-85ae-99ac41c6181e",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:33.464264Z",
     "start_time": "2023-06-27T17:44:33.441937Z"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6134506251022499"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare to other models"
   ],
   "metadata": {
    "id": "Z19791r1uB-M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import \\\n",
    "    MLPRegressor  # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "regr = MLPRegressor(random_state=42, max_iter=5000, learning_rate_init=0.1)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ],
   "metadata": {
    "id": "taWAXfzzdMtH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740251271,
     "user_tz": 360,
     "elapsed": 815,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "e6af8295-878e-4ace-8a39-1bba604aa831",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:36.623732Z",
     "start_time": "2023-06-27T17:44:36.424119Z"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5404269965780658"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import \\\n",
    "    GradientBoostingRegressor  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ],
   "metadata": {
    "id": "_UidFLTtEUrg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740255371,
     "user_tz": 360,
     "elapsed": 593,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "6266993a-2351-4cb9-cd4d-a7ba925d041c",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:44:37.635427Z",
     "start_time": "2023-06-27T17:44:37.470888Z"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7570735169219105"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment: add one or more Dropout layers"
   ],
   "metadata": {
    "id": "eo4MeW6zHv9F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_hidden = X_train.shape[1] * 2\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetworkWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkWithDropout, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(X_train.shape[1], n_hidden)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)  # Adding the first dropout layer with a dropout probability of 0.5\n",
    "        self.linear2 = nn.Linear(n_hidden, 4)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)  # Adding the second dropout layer with a dropout probability of 0.5\n",
    "        self.linear3 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)  # Applying dropout after the first linear layer\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)  # Applying dropout after the second linear layer\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "model = NeuralNetworkWithDropout()\n",
    "\n",
    "# Use the above function to train the network\n",
    "model = train_network(model, train_loader)\n",
    "\n",
    "# Score the model performance\n",
    "score_model(model, X_test_tensor, y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w68h82nrH04S",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740436372,
     "user_tz": 360,
     "elapsed": 5684,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "d4490181-6881-44be-945d-70a8f5fe57d6",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:47:09.858167Z",
     "start_time": "2023-06-27T17:47:08.652Z"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 248531732.8888889\n",
      "Epoch 11 loss: 208150588.44444445\n",
      "Epoch 21 loss: 214490024.0\n",
      "Epoch 31 loss: 215228393.7777778\n",
      "Epoch 41 loss: 219806314.66666666\n",
      "Epoch 51 loss: 185647411.1111111\n",
      "Epoch 61 loss: 182193380.8888889\n",
      "Epoch 71 loss: 187527616.44444445\n",
      "Epoch 81 loss: 206875252.8888889\n",
      "Epoch 91 loss: 211799203.1111111\n",
      "Epoch 101 loss: 186291504.0\n",
      "Epoch 111 loss: 199123481.7777778\n",
      "Epoch 121 loss: 210563665.33333334\n",
      "Epoch 131 loss: 186837834.66666666\n",
      "Epoch 141 loss: 210233454.2222222\n",
      "Epoch 151 loss: 211570598.2222222\n",
      "Epoch 161 loss: 202407586.2222222\n",
      "Epoch 171 loss: 182315229.33333334\n",
      "Epoch 181 loss: 192921482.2222222\n",
      "Epoch 191 loss: 190037414.66666666\n"
     ]
    },
    {
     "data": {
      "text/plain": "-0.4485606451966506"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment: Add one or more Batch normalization layers"
   ],
   "metadata": {
    "id": "BHE5VPS3H3QU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_hidden = X_train.shape[1] * 2\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetworkWithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkWithBN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(X_train.shape[1], n_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)  # Adding batch normalization after the first linear layer\n",
    "        self.linear2 = nn.Linear(n_hidden, 4)\n",
    "        self.bn2 = nn.BatchNorm1d(4)  # Adding batch normalization after the second linear layer\n",
    "        self.linear3 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)  # Applying batch normalization after the first linear layer\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.bn2(x)  # Applying batch normalization after the second linear layer\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "model = NeuralNetworkWithBN()\n",
    "\n",
    "# Use the above function to train the network\n",
    "model = train_network(model, train_loader, verbose=False)\n",
    "\n",
    "# Score the model performance\n",
    "score_model(model, X_test_tensor, y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJTB3z52H18v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740354283,
     "user_tz": 360,
     "elapsed": 8971,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "c511ae9e-f75e-434c-ab8e-57e48185d995",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:49:23.644900Z",
     "start_time": "2023-06-27T17:49:20.021765Z"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6377187514133751"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tuning NN hyperparameters"
   ],
   "metadata": {
    "id": "ZuBfWd5W5r1v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "\n",
    "# First, define a wrapper class for the PyTorch model\n",
    "class NeuralNetwork(nn.Module, BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_size=10, hidden_size=64, pre_final_hidden_size=4,\n",
    "                 output_size=1, lr=0.01, dropout_prob=0.01):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pre_final_hidden_size = pre_final_hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.num_epochs = 100\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn0 = nn.BatchNorm1d(X_train.shape[1])\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(self.dropout_prob)\n",
    "        self.linear2 = nn.Linear(hidden_size, pre_final_hidden_size)\n",
    "        self.linear3 = nn.Linear(pre_final_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self(X_test_tensor).numpy()\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Second, create a parameter grid specifying the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'hidden_size': [64, 128, 256],\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'dropout_prob': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Third, create an instance of GridSearchCV\n",
    "model = NeuralNetwork(input_size=X_train.shape[1], output_size=1)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=scorer, cv=3, verbose=2)\n",
    "\n",
    "# Then, fit GridSearchCV on your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Finally, access the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Model:\", best_model)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afk0zKh8-4TB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740737944,
     "user_tz": 360,
     "elapsed": 133670,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "f4103aa0-1761-406f-b320-ee8e57e2326f",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:10.942823Z",
     "start_time": "2023-06-27T17:50:17.639919Z"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=64, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=64, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=64, lr=0.001; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.001, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.001, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.001, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=128, lr=0.001; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=128, lr=0.001; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=128, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=128, lr=0.01; total time=   1.8s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=128, lr=0.01; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=128, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END ......dropout_prob=0.001, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.001, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=256, lr=0.1; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=256, lr=0.1; total time=   1.3s\n",
      "[CV] END ........dropout_prob=0.001, hidden_size=256, lr=0.1; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=64, lr=0.001; total time=   1.2s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=64, lr=0.001; total time=   1.6s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=64, lr=0.001; total time=   1.1s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=64, lr=0.01; total time=   0.9s\n",
      "[CV] END ..........dropout_prob=0.01, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END ..........dropout_prob=0.01, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END ..........dropout_prob=0.01, hidden_size=64, lr=0.1; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=128, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=128, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=128, lr=0.001; total time=   1.1s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=128, lr=0.01; total time=   1.0s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=128, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=128, lr=0.01; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=128, lr=0.1; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END .......dropout_prob=0.01, hidden_size=256, lr=0.001; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END ........dropout_prob=0.01, hidden_size=256, lr=0.01; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=256, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=256, lr=0.1; total time=   0.9s\n",
      "[CV] END .........dropout_prob=0.01, hidden_size=256, lr=0.1; total time=   0.9s\n",
      "Best Hyperparameters: {'dropout_prob': 0.01, 'hidden_size': 256, 'lr': 0.1}\n",
      "Best Model: NeuralNetwork(\n",
      "  (criterion): MSELoss()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (bn0): BatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear1): Linear(in_features=17, out_features=256, bias=True)\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.01, inplace=False)\n",
      "  (linear2): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (linear3): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udOpU8e1_cHp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740737947,
     "user_tz": 360,
     "elapsed": 23,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "356dc645-d271-46d5-8bde-ec6051f605d9",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:10.954301Z",
     "start_time": "2023-06-27T17:51:10.944552Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6362522453219757"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment:\n",
    "**Change the hyperparameters of the Neural Network such that the prediction score is closer to the one of the Gradient Boosting model**"
   ],
   "metadata": {
    "id": "cS0arhZFNOrk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New challenge: Classification"
   ],
   "metadata": {
    "id": "UzM3wWLTBXS4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "\n",
    "Predictive maintenance: Equipment failure and downtime can be costly for energy infrastructure, such as power plants and transmission systems. Machine learning algorithms can analyze sensor data, historical maintenance records, and other relevant data to predict equipment failures and identify maintenance requirements proactively. This enables energy companies to schedule maintenance activities more effectively, reduce downtime, and optimize maintenance costs."
   ],
   "metadata": {
    "id": "ETNBoThqBbt4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "new_df = pd.read_csv('sensor_data_maintenance.csv')\n",
    "new_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "0isgYjnzBZLo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740854715,
     "user_tz": 360,
     "elapsed": 1212,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "6534c03b-3fc5-422c-eb65-6a6b84266eaf",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:11.022767Z",
     "start_time": "2023-06-27T17:51:10.950097Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  Sensor_1  Sensor_2  Sensor_3  Sensor_4  Sensor_5  Sensor_6   \n0           0 -1.583773 -1.244331 -0.113223 -1.087246 -1.186680 -0.690355  \\\n1           1 -0.039139  0.980477  1.379957  0.497047 -1.360191  1.321492   \n2           2  0.152440 -2.348545 -1.728102 -0.077548  0.554057 -0.225785   \n3           3  1.275449  0.372947 -1.161504  2.362207 -0.299641  0.184730   \n4           4 -0.248560 -1.078426 -0.057282 -0.123365 -0.088669 -1.155219   \n\n   Sensor_7  Sensor_8  Sensor_9  ...  Sensor_12  Sensor_13  Sensor_14   \n0 -1.038473  0.345244 -1.325520  ...  -0.492003   0.990395   0.932278  \\\n1  0.629370  0.182280 -1.181035  ...  -0.299087   0.911204   0.424911   \n2  0.225522 -0.390812  0.518928  ...  -0.020434   0.003841   0.055826   \n3  0.399616  1.297538  0.591856  ...  -0.301737   0.323409   0.702024   \n4  2.042568  0.542607 -0.347265  ...  -0.319895   1.562805   0.184635   \n\n   Sensor_15  Sensor_16  Sensor_17  Sensor_18  Sensor_19  Sensor_20   \n0   0.216999   1.020084  -0.026296   0.521321  -0.364502  -1.308543  \\\n1   0.154348   1.792933   0.547381   1.930945   0.781602   0.863269   \n2   0.339131  -1.764101  -0.069050  -0.282374  -1.052295  -0.299364   \n3   0.252096   0.733678  -0.533636   1.070523   1.030613   1.093862   \n4  -1.101577  -0.599507   1.657374  -0.113839  -1.590337  -1.940206   \n\n   Needs_maintenance  \n0                  1  \n1                  1  \n2                  0  \n3                  1  \n4                  0  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Sensor_1</th>\n      <th>Sensor_2</th>\n      <th>Sensor_3</th>\n      <th>Sensor_4</th>\n      <th>Sensor_5</th>\n      <th>Sensor_6</th>\n      <th>Sensor_7</th>\n      <th>Sensor_8</th>\n      <th>Sensor_9</th>\n      <th>...</th>\n      <th>Sensor_12</th>\n      <th>Sensor_13</th>\n      <th>Sensor_14</th>\n      <th>Sensor_15</th>\n      <th>Sensor_16</th>\n      <th>Sensor_17</th>\n      <th>Sensor_18</th>\n      <th>Sensor_19</th>\n      <th>Sensor_20</th>\n      <th>Needs_maintenance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-1.583773</td>\n      <td>-1.244331</td>\n      <td>-0.113223</td>\n      <td>-1.087246</td>\n      <td>-1.186680</td>\n      <td>-0.690355</td>\n      <td>-1.038473</td>\n      <td>0.345244</td>\n      <td>-1.325520</td>\n      <td>...</td>\n      <td>-0.492003</td>\n      <td>0.990395</td>\n      <td>0.932278</td>\n      <td>0.216999</td>\n      <td>1.020084</td>\n      <td>-0.026296</td>\n      <td>0.521321</td>\n      <td>-0.364502</td>\n      <td>-1.308543</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.039139</td>\n      <td>0.980477</td>\n      <td>1.379957</td>\n      <td>0.497047</td>\n      <td>-1.360191</td>\n      <td>1.321492</td>\n      <td>0.629370</td>\n      <td>0.182280</td>\n      <td>-1.181035</td>\n      <td>...</td>\n      <td>-0.299087</td>\n      <td>0.911204</td>\n      <td>0.424911</td>\n      <td>0.154348</td>\n      <td>1.792933</td>\n      <td>0.547381</td>\n      <td>1.930945</td>\n      <td>0.781602</td>\n      <td>0.863269</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.152440</td>\n      <td>-2.348545</td>\n      <td>-1.728102</td>\n      <td>-0.077548</td>\n      <td>0.554057</td>\n      <td>-0.225785</td>\n      <td>0.225522</td>\n      <td>-0.390812</td>\n      <td>0.518928</td>\n      <td>...</td>\n      <td>-0.020434</td>\n      <td>0.003841</td>\n      <td>0.055826</td>\n      <td>0.339131</td>\n      <td>-1.764101</td>\n      <td>-0.069050</td>\n      <td>-0.282374</td>\n      <td>-1.052295</td>\n      <td>-0.299364</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.275449</td>\n      <td>0.372947</td>\n      <td>-1.161504</td>\n      <td>2.362207</td>\n      <td>-0.299641</td>\n      <td>0.184730</td>\n      <td>0.399616</td>\n      <td>1.297538</td>\n      <td>0.591856</td>\n      <td>...</td>\n      <td>-0.301737</td>\n      <td>0.323409</td>\n      <td>0.702024</td>\n      <td>0.252096</td>\n      <td>0.733678</td>\n      <td>-0.533636</td>\n      <td>1.070523</td>\n      <td>1.030613</td>\n      <td>1.093862</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-0.248560</td>\n      <td>-1.078426</td>\n      <td>-0.057282</td>\n      <td>-0.123365</td>\n      <td>-0.088669</td>\n      <td>-1.155219</td>\n      <td>2.042568</td>\n      <td>0.542607</td>\n      <td>-0.347265</td>\n      <td>...</td>\n      <td>-0.319895</td>\n      <td>1.562805</td>\n      <td>0.184635</td>\n      <td>-1.101577</td>\n      <td>-0.599507</td>\n      <td>1.657374</td>\n      <td>-0.113839</td>\n      <td>-1.590337</td>\n      <td>-1.940206</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y = new_df['Needs_maintenance']\n",
    "X = new_df.drop(['Needs_maintenance'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "id": "l-1hTREmGweV",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:11.022966Z",
     "start_time": "2023-06-27T17:51:10.999311Z"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train a classification network"
   ],
   "metadata": {
    "id": "iP-Mn-LlTivW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ClassificationNeuralNetwork(nn.Module, BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_size=20, hidden_size=64, pre_final_hidden_size=16,\n",
    "                 output_size=2, lr=0.001, dropout_prob=0.02):\n",
    "        super(ClassificationNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pre_final_hidden_size = pre_final_hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lr = lr\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.num_epochs = 30\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn0 = nn.BatchNorm1d(X_train.shape[1])\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(self.dropout_prob)\n",
    "        self.linear2 = nn.Linear(hidden_size, pre_final_hidden_size)\n",
    "        self.linear3 = nn.Linear(pre_final_hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)  # The last layer should be a softmax or sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                # forward\n",
    "                outputs = self(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # print the loss every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{self.num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self(X_test_tensor).numpy()\n",
    "        return predictions.argmax(1).astype(int)"
   ],
   "metadata": {
    "id": "cJKqebnjNR4T",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:11.023110Z",
     "start_time": "2023-06-27T17:51:11.017065Z"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_params['input_size'] = X_train.shape[1]\n",
    "best_params['output_size'] = len(y_train.unique())"
   ],
   "metadata": {
    "id": "zpA83U2nPB-y",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:11.023172Z",
     "start_time": "2023-06-27T17:51:11.017346Z"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_cl = ClassificationNeuralNetwork(input_size=X_train.shape[1])\n",
    "model_cl.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "gkeEb4dlHiBW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740961397,
     "user_tz": 360,
     "elapsed": 9718,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "0e4d11da-9adc-4d57-c03d-9bb4ae7995d9",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:14.612331Z",
     "start_time": "2023-06-27T17:51:11.017518Z"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.5820\n",
      "Epoch [20/30], Loss: 0.5398\n",
      "Epoch [30/30], Loss: 0.5641\n"
     ]
    },
    {
     "data": {
      "text/plain": "ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassificationNeuralNetwork</label><div class=\"sk-toggleable__content\"><pre>ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)</pre></div></div></div></div></div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {
    "id": "dwwYefrnTn8D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model_cl.predict(X_test)\n",
    "\n",
    "scores = classification_report(y_test.values, y_pred)\n",
    "print(scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dV7A7uhrQdyz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687740966554,
     "user_tz": 360,
     "elapsed": 256,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "b9a6c0bb-e460-45cd-abcd-7f99e5f1d690",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:14.623211Z",
     "start_time": "2023-06-27T17:51:14.614142Z"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1647\n",
      "           1       0.77      0.76      0.77      1653\n",
      "\n",
      "    accuracy                           0.77      3300\n",
      "   macro avg       0.77      0.77      0.77      3300\n",
      "weighted avg       0.77      0.77      0.77      3300\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare to other models"
   ],
   "metadata": {
    "id": "oCj2je_dTuun"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import \\\n",
    "    GradientBoostingClassifier  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "scores = classification_report(y_test, y_pred)\n",
    "print(scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-rZbQd0Sn8y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1687741016950,
     "user_tz": 360,
     "elapsed": 6339,
     "user": {
      "displayName": "Ilja Rausch",
      "userId": "09224443308545937385"
     }
    },
    "outputId": "4ff931a5-3553-4236-c14e-c79dc9fff20e",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:17.772247Z",
     "start_time": "2023-06-27T17:51:14.626654Z"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1647\n",
      "           1       0.81      0.83      0.82      1653\n",
      "\n",
      "    accuracy                           0.82      3300\n",
      "   macro avg       0.82      0.82      0.82      3300\n",
      "weighted avg       0.82      0.82      0.82      3300\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment:\n",
    "**Change the hyperparameters of the Neural Network such that the prediction score is closer to the one of the Gradient Boosting model**"
   ],
   "metadata": {
    "id": "nGumE5QbNlHe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Find Gradient Boosting Model prediction score\n",
    "# TODO\n",
    "\n",
    "# Change the hyperparameters of the NN to improve the prediction score\n",
    "hyperparameters = {\n",
    "    'input_size': X_train.shape[1],\n",
    "    # FIXME check RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x21 and 20x64)\n",
    "    'hidden_size': 64,\n",
    "    'pre_final_hidden_size': 16,\n",
    "    'output_size': len(y_train.unique()),\n",
    "    'lr': 0.001,\n",
    "    'dropout_prob': 0.02\n",
    "}\n",
    "\n",
    "# PRINT ORIGINAL SCORES\n",
    "print(f\"CL score: {0.78}\")\n",
    "print(f\"GBC score: {0.80}\")\n",
    "\n",
    "model_cl_ht = model_cl\n",
    "model_cl_ht.set_params(**hyperparameters)\n",
    "\n",
    "model_cl_ht.fit(X_train, y_train)\n",
    "\n",
    "# FIXME RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x21 and 20x64)"
   ],
   "metadata": {
    "id": "e-Pa37FQxECU",
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:21.702219Z",
     "start_time": "2023-06-27T17:51:17.773466Z"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL score: 0.78\n",
      "GBC score: 0.8\n",
      "Epoch [10/30], Loss: 0.4815\n",
      "Epoch [20/30], Loss: 0.6380\n",
      "Epoch [30/30], Loss: 0.5109\n"
     ]
    },
    {
     "data": {
      "text/plain": "ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassificationNeuralNetwork</label><div class=\"sk-toggleable__content\"><pre>ClassificationNeuralNetwork(\n  (criterion): CrossEntropyLoss()\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (bn0): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear1): Linear(in_features=21, out_features=64, bias=True)\n  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.02, inplace=False)\n  (linear2): Linear(in_features=64, out_features=16, bias=True)\n  (linear3): Linear(in_features=16, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)</pre></div></div></div></div></div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T17:51:21.703792Z",
     "start_time": "2023-06-27T17:51:21.701418Z"
    }
   }
  }
 ]
}
